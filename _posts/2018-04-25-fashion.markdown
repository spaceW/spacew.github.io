---
title:  Dialog-based Interactive Image Retrieval
date:   2018-04-25
thumb:  /media/fashion_framework.jpg
paper_name: Dialog-based Interactive Image Retrieval
conf_name: arXiv preprint 2018
paper_authors: Xiaoxiao Guo*, Hui Wu*, Yu Cheng, Steve Rennie and Rogerio Feris (* equal contribution)
paper_pdf: https://arxiv.org/abs/1805.00145
paper_video: https://www.youtube.com/watch?v=6sabCmwO4So
paper_code: https://raw.githubusercontent.com/spacew/spacew.github.io/master/media/message.txt
---

### Overview

We proposed a novel type of _dialog agent_ for the task of _interactive image retrieval_. 
Recently, there has been a rapid rise of research interest in visually grounded conversational 
agents, driven by the progress of deep learning techniques for both image and natural 
language understanding. A few interesting application scenarios have been explored by 
recent work, such as collaborative drawing, visual dialog and object guessing game. 
In this work, we tested the value of visually grounded dialog agents in a practical and yet
challenging context. Specicially, we proposed a novel framework of image retrieval system which learns to seek 
natural and expressive dialog feedbacks from the user and iteratively refine the retrieval result. 


<!--more-->

<img alt="img" src="{{site.baseurl}}/media/feedback.jpg">

<br/>
### Goal-oriented Training of Dialog Manager
When designing an interactive image retrieval system, deciding on which images to return to the users
at each interaction round and how to aggregate the user feedback in a principled way are the essential 
problems to be addressed. The desired behavior of the retrieval system is to learn how to construct 
the optimal sequence of candidate images to obtain the most informative user feedbacks. 
Instead of specifying the rules for candidate image selection and feedback
aggregation, we let the retrieval system (which we call _dialog manager_) automatically learn to 
optimize the retrieval objective, which is the ranking percentile of the target image. To the best of our knowledge, 
this is the first time goal-oriented training being applied to the context of interactive image retrieval.

Below is the network architecture for our dialog manager, which consists of (1) a response encoder that
combines the candidate image from the previous round and the natural language feedback, (2) a history encoder
for aggregating the new evidence and the dialog history and (3) a candidate image selector, which is simply
stochastic kNN during training and 1-NN during testing. 

<img alt="img" src="{{site.baseurl}}/media/fashion_framework.jpg">

<br/>
### User Simulator using Relative Captioning 
One challenge remains in order to train the dialog management in a goal-oriended, end-to-end fashion: 
how do we obtain user feedbacks? The natural approach is to train the dialog manager in an online way
with human annotator in the loop. However, this procedure could be prohibitively slow and expensive.
Think about the case: it takes about one minute to collect one set of dialog with 10 rounds of interactions. 
So 120k sets of training dialogs requires 2k hours of annotation effort!

To this end, we 

We therefore devised a new vision task: relative image captioning, which aims to serve as a proxy of human annotators and helps to train the dialog agent. The idea is simple: given a pair of images, how do humans describe their visual differences in natural language. To this end, we collected a dataset for relative image captioning (which will be released) and trained a show-attend-tell based captioning generator. See below for generated image captions: 

<img alt="img" src="{{site.baseurl}}/media/relative_example.jpg">

<br/>
### Code and Dataset 
We are working on details of code and data release and will give an update soon. 
Meanwhile, below is a video showcasing an user interacting with the dialog manager. 
I used SlackBot for the first version of the implementation due to its conveninent API for reading messages. 
But it has restrictions on extending the demo to multiple images per round and letting the user to 
choose the image to provide feedback on. 

<a href="http://www.youtube.com/watch?v=6sabCmwO4So"><img alt="img" src="{{site.baseurl}}/media/fashion_video_snip.jpeg"></a>

<br/>
### Reference

<p>
  [1] Xiaoxiao Guo*, Hui Wu*, Yu Cheng, Steven Rennie, and Rogerio Schmidt Feris. "Dialog-based Interactive Image Retrieval." arXiv preprint arXiv:1805.00145 (2018).(* equal contribution)
</p>

